import torch
from transformers import BertTokenizer, BertForSequenceClassification
import pandas as pd

class IntentClassifier:
    """Intent classification inference with response mapping"""
    
    def __init__(self, model_path, device='cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        
        # Load checkpoint
        print(f"Loading model from {model_path}...")
        checkpoint = torch.load(model_path, map_location=self.device)
        
        # Extract metadata
        self.label2id = checkpoint['label2id']
        self.id2label = checkpoint['id2label']
        self.tokenizer_name = checkpoint['tokenizer_name']
        self.max_len = checkpoint['max_len']
        
        # Load tokenizer and model
        self.tokenizer = BertTokenizer.from_pretrained(self.tokenizer_name)
        self.model = BertForSequenceClassification.from_pretrained(
            self.tokenizer_name, 
            num_labels=len(self.label2id)
        )
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        print(f"âœ… Model loaded successfully!")
        print(f"Device: {self.device}")
        print(f"Classes: {list(self.id2label.values())}")
        
        # Response templates based on promotional scripts
        self.response_templates = self._load_response_templates()
    
    def _load_response_templates(self):
        """Load response templates for each intent"""
        return {
            "fee_question": [
                "ë³´í—˜ë£Œì˜ 7%ë¥¼ ì†Œê°œë£Œë¡œ ìµì¼ ì§€ê¸‰í•´ë“œë¦½ë‹ˆë‹¤.",
                "ìˆ˜ìˆ˜ë£ŒëŠ” 7í”„ë¡œì´ë©°, ìµì¼ ì˜¤í›„ì— ë°”ë¡œ ì§€ê¸‰ë©ë‹ˆë‹¤.",
                "OFF, TM, CM ê°€ì… ëª¨ë‘ 7% ìˆ˜ìˆ˜ë£Œë¥¼ ìµì¼ì— ë°”ë¡œ ì§€ê¸‰í•´ë“œë¦¬ê³  ìˆìŠµë‹ˆë‹¤."
            ],
            "about_company": [
                "ì €í¬ëŠ” 40ë…„ ì „í†µì˜ ì¸ìŠˆë„· FC ìíšŒì‚¬ ì°¨ì§‘ì‚¬ ë‹¤ì´ë ‰íŠ¸ì…ë‹ˆë‹¤.",
                "ì°¨ì§‘ì‚¬ëŠ” ì¸ìŠˆë„· FC ì œíœ´ì‚¬ë¡œ ì •ì‹ ë“±ë¡ëœ ë³´í—˜ ë¹„êµ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.",
                "ì €í¬ëŠ” ë³´í—˜ì‚¬ ì—°ë„ëŒ€ìƒì ì¶œì‹ ë“¤ë¡œ êµ¬ì„±ëœ ì „ë¬¸ íŒ€ì…ë‹ˆë‹¤."
            ],
            "more_questions": [
                "ë‹¤ì´ë ‰íŠ¸ ë³´í—˜ë£Œë¥¼ 10ë¶„ ë‚´ ë¹„êµí•´ë“œë¦¬ê³ , AI ARS 1668-4007ë¡œ ê¸´ê¸‰ì¶œë™ ì„œë¹„ìŠ¤ë„ ì œê³µí•©ë‹ˆë‹¤.",
                "ê°€ì… í›„ì—ëŠ” ë”œëŸ¬ë‹˜ê»˜ ë³´í—˜ ê´€ë ¨ ì—°ë½ì´ ê°€ì§€ ì•Šë„ë¡ AI ë²ˆí˜¸ë¥¼ ìš´ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                "ë³´í—˜ì‚¬ ì§ì ‘ ì—°ê²° ì„œë¹„ìŠ¤ì™€ ì‚¬ê³  ì‹œ ê¸´ê¸‰ì¶œë™ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤."
            ],
            "positive": [
                "ê°ì‚¬í•©ë‹ˆë‹¤! ëª…í•¨ ë¬¸ìë¡œ ë‚¨ê²¨ë“œë¦´ê²Œìš”. ì•ìœ¼ë¡œ ì œê°€ ë‹´ë‹¹ì´ë‹ˆ ì—°ë½ ì£¼ì„¸ìš”.",
                "ê°ì‚¬í•©ë‹ˆë‹¤. ê²¬ì  ë¬¸ì˜ ìˆìœ¼ì‹¤ ë•Œ ì—°ë½ ì£¼ì‹œë©´ ë¹ ë¥´ê²Œ ì§„í–‰ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                "ì¢‹ìŠµë‹ˆë‹¤! CU ëª¨ë°”ì¼ ìƒí’ˆê¶Œë„ ë“œë¦¬ë‹ˆ ì²« ë¬¸ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
            ],
            "rejection": [
                "ì•Œê² ìŠµë‹ˆë‹¤. í˜¹ì‹œ ë‚˜ì¤‘ì— í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ì—°ë½ ì£¼ì„¸ìš”.",
                "ë„¤, ì´í•´í•©ë‹ˆë‹¤. ëª…í•¨ë§Œ ë‚¨ê²¨ë“œë¦´ê²Œìš”. ë‚˜ì¤‘ì— í•„ìš”í•˜ì‹œë©´ í¸í•˜ê²Œ ì—°ë½ ì£¼ì„¸ìš”.",
                "ê´œì°®ìŠµë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”. ê°ì‚¬í•©ë‹ˆë‹¤."
            ],
            "other": [
                "í˜„ì¬ ê±°ë˜ì²˜ê°€ ìˆìœ¼ì‹œêµ°ìš”. ì €í¬ëŠ” ìˆ˜ìˆ˜ë£Œ 7%ì™€ ì²´ê²°ìœ¨ 95% ì´ìƒì˜ ì¡°ê±´ì„ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                "ì´í•´í•©ë‹ˆë‹¤. í˜¹ì‹œ ë¹„êµí•´ë³´ì‹œê³  ì‹¶ìœ¼ì‹œë©´ ì–¸ì œë“  ì—°ë½ ì£¼ì„¸ìš”.",
                "ë„¤, ì €í¬ëŠ” ì¡°ê±´ì´ ë” ì¢‹ì•„ ë§ì€ ë¶„ë“¤ì´ í•¨ê»˜ í•˜ê³  ê³„ì‹­ë‹ˆë‹¤. í•œë²ˆ ë¹„êµí•´ë³´ì‹œëŠ” ê²ƒë„ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤."
            ],
            "fallback": [
                "ëª…í•¨ê³¼ ìƒì„¸ ìë£Œë¥¼ ë¬¸ìë¡œ ë³´ë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                "ì¹´ì¹´ì˜¤í†¡ìœ¼ë¡œë„ ìë£Œ ì „ë‹¬ ê°€ëŠ¥í•©ë‹ˆë‹¤. ìƒë‹´ì› ì—°ê²°ë„ ë„ì™€ë“œë¦´ê²Œìš”.",
                "ë„¤, ê´€ë ¨ ìë£Œ ì „ë¶€ ë³´ë‚´ë“œë¦¬ê³  ë‹´ë‹¹ì ì§ì ‘ ì—°ê²°í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            ],
            "greeting": [
                "ì•ˆë…•í•˜ì„¸ìš”! ì°¨ì§‘ì‚¬ ë‹¤ì´ë ‰íŠ¸ì…ë‹ˆë‹¤. ì ì‹œ í†µí™” ê°€ëŠ¥í•˜ì‹¤ê¹Œìš”?",
                "ë„¤, ì•ˆë…•í•˜ì„¸ìš”. ìë™ì°¨ ë³´í—˜ ë¹„êµ ê°€ì… ë„ì™€ë“œë¦¬ëŠ” ì°¨ì§‘ì‚¬ì…ë‹ˆë‹¤.",
                "ì•ˆë…•í•˜ì„¸ìš”~ ì˜¤ëŠ˜ ë¬¸ì ë³´ë‚´ë“œë ¸ëŠ”ë°ìš”, ì ê¹ ì•ˆë‚´ ë§ì”€ ë“œë ¤ë„ ë ê¹Œìš”?"
            ]
        }
    
    def predict(self, text, return_probs=False):
        """Predict intent for a single text"""
        encoding = self.tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=self.max_len,
            truncation=True,
            padding="max_length",
            return_tensors="pt",
            return_attention_mask=True,
            return_token_type_ids=False
        )
        
        input_ids = encoding["input_ids"].to(self.device)
        attention_mask = encoding["attention_mask"].to(self.device)
        
        with torch.no_grad():
            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=1)
            pred_id = torch.argmax(probs, dim=1).item()
            confidence = probs[0][pred_id].item()
        
        intent = self.id2label[pred_id]
        
        if return_probs:
            all_probs = {self.id2label[i]: probs[0][i].item() 
                        for i in range(len(self.id2label))}
            return intent, confidence, all_probs
        
        return intent, confidence
    
    def predict_batch(self, texts):
        """Predict intents for multiple texts"""
        results = []
        for text in texts:
            intent, confidence = self.predict(text)
            results.append({
                'text': text,
                'intent': intent,
                'confidence': confidence
            })
        return pd.DataFrame(results)
    
    def get_response(self, text, intent=None):
        """Get appropriate response for dealer's text"""
        if intent is None:
            intent, confidence = self.predict(text)
        else:
            _, confidence = self.predict(text)
        
        # Get response template
        templates = self.response_templates.get(intent, ["ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ í•œë²ˆ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"])
        response = templates[0]  # Can randomize or use logic to select
        
        return {
            'dealer_text': text,
            'detected_intent': intent,
            'confidence': confidence,
            'agent_response': response
        }
    
    def interactive_test(self):
        """Interactive testing mode"""
        print("\n" + "="*60)
        print("ğŸ¤– Interactive Intent Classification Test")
        print("Type 'quit' to exit")
        print("="*60 + "\n")
        
        while True:
            user_input = input("ë”œëŸ¬ ì‘ë‹µ: ").strip()
            
            if user_input.lower() == 'quit':
                print("Goodbye!")
                break
            
            if not user_input:
                continue
            
            intent, confidence, all_probs = self.predict(user_input, return_probs=True)
            response_data = self.get_response(user_input, intent)
            
            print(f"\n{'â”€'*60}")
            print(f"ğŸ¯ Intent: {intent} (Confidence: {confidence:.2%})")
            print(f"\nğŸ“Š All Probabilities:")
            for label, prob in sorted(all_probs.items(), key=lambda x: x[1], reverse=True):
                bar = "â–ˆ" * int(prob * 30)
                print(f"  {label:20s} {prob:6.2%} {bar}")
            print(f"\nğŸ’¬ Agent Response:")
            print(f"  {response_data['agent_response']}")
            print(f"{'â”€'*60}\n")


def test_on_samples():
    """Test classifier on sample dealer responses"""
    classifier = IntentClassifier('./model/best_model.pth')
    
    test_samples = [
        "ëª‡ í¼ì„¼íŠ¸ ì£¼ì‹œëŠ” ê±°ì˜ˆìš”?",
        "ì°¨ì§‘ì‚¬ê°€ ì–´ë””ì—ìš”?",
        "ê³ ê°ì´ ê±°ë¶€í•˜ë©´ ì–´ë–»ê²Œ ë˜ì£ ?",
        "ì˜¤ ê´œì°®ì€ë°ìš”",
        "ì•ˆ í•´ìš” ì§€ê¸ˆì€",
        "ì € ë‹¤ë¥¸ ë° í•˜ê³  ìˆì–´ì„œìš”",
        "ëª…í•¨ ì¢€ ë³´ë‚´ì£¼ì„¸ìš”",
        "ì•ˆë…•í•˜ì„¸ìš”",
    ]
    
    print("\n" + "="*60)
    print("ğŸ“‹ Testing on Sample Dealer Responses")
    print("="*60 + "\n")
    
    for sample in test_samples:
        result = classifier.get_response(sample)
        print(f"Dealer: {result['dealer_text']}")
        print(f"Intent: {result['detected_intent']} ({result['confidence']:.2%})")
        print(f"Agent: {result['agent_response']}")
        print(f"{'â”€'*60}\n")


if __name__ == "__main__":
    # Run tests
    test_on_samples()
    
    # Optional: Start interactive mode
    # classifier = IntentClassifier('./model/best_model.pth')
    # classifier.interactive_test()
