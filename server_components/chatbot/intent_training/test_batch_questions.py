"""
Comprehensive test suite for intent classification and response generation.
Tests determinism, context-awareness, and response variety.
"""

import requests
import json
import time
from typing import Dict, List, Tuple
from collections import defaultdict

# ============================================================
# CONFIG
# ============================================================
URL = "https://honest-trivially-buffalo.ngrok-free.app/respond"
# URL = "https://f8d5daa0897b.ngrok-free.app/respond"

HEADERS = {
    "Content-Type": "application/json"
}

# ============================================================
# TEST CASES - Organized by Intent
# ============================================================
TEST_CASES = {
    "fee_question": {
        "amount": [
            "ëª‡ í”„ë¡œì—ìš”?",
            "ìˆ˜ìˆ˜ë£Œ ëª‡ %ì—ìš”?",
            "ì–¼ë§ˆ ì£¼ì‹œë‚˜ìš”?",
            "ëª‡ í¼ì„¼íŠ¸ì£ ?",
        ],
        "timing": [
            "ì–¸ì œ ìž…ê¸ˆë¼ìš”?",
            "ì§€ê¸‰ ì‹œì ì€ ì–¸ì œì˜ˆìš”?",
            "ìµì¼ì´ë©´ ì–¸ì œì˜ˆìš”?",
            "ë°”ë¡œ ì£¼ëŠ” ê±°ì˜ˆìš”?",
        ],
        "method": [
            "ì–´ë–»ê²Œ ì§€ê¸‰í•˜ë‚˜ìš”?",
            "ê³„ì¢Œë¡œ ë“¤ì–´ì˜¤ë‚˜ìš”?",
            "ì§€ê¸‰ ë°©ë²•ì€ìš”?",
        ],
        "tax": [
            "ì„¸ê¸ˆì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ì›ì²œì§•ìˆ˜ í•˜ë‚˜ìš”?",
            "3.3% ë–¼ë‚˜ìš”?",
        ],
        "scope": [
            "ë‹¤ì´ë ‰íŠ¸ë„ 7%ì¸ê°€ìš”?",
            "ì‚¼ì„±ë„ í¬í•¨ë¼ìš”?",
            "ì˜¤í”„ë¼ì¸ë„ ë˜ë‚˜ìš”?",
        ]
    },
    "about_company": {
        "identity": [
            "ì°¨ì§‘ì‚¬ê°€ ì–´ë””ì—ìš”?",
            "ì–´ëŠ íšŒì‚¬ì£ ?",
            "íšŒì‚¬ ì´ë¦„ì´ ë­ì˜ˆìš”?",
        ],
        "legitimacy": [
            "ì •ì‹ ì—…ì²´ì˜ˆìš”?",
            "ë“±ë¡ëœ íšŒì‚¬ì¸ê°€ìš”?",
            "ë¯¿ì„ ìˆ˜ ìžˆë‚˜ìš”?",
        ],
        "relationship": [
            "ë³´í—˜ì‚¬ëž‘ ë¬´ìŠ¨ ê´€ê³„ì˜ˆìš”?",
            "ì œíœ´ì‚¬ì˜ˆìš”?",
            "ì§ì˜ì¸ê°€ìš”?",
        ]
    },
    "more_questions": {
        "process": [
            "ì ˆì°¨ê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?",
            "ë°©ë²• ì¢€ ì•Œë ¤ì£¼ì„¸ìš”",
        ],
        "features": [
            "ARSê°€ ë­ì˜ˆìš”?",
            "ê¸´ê¸‰ì¶œë™ë„ ë˜ë‚˜ìš”?",
            "ì–´ë–¤ ì„œë¹„ìŠ¤ ìžˆì–´ìš”?",
        ]
    },
    "positive": {
        "interested": [
            "ì˜¤ ê´œì°®ë„¤ìš”",
            "ì¢‹ì€ë°ìš”",
            "ê´œì°®ì€ ê²ƒ ê°™ì•„ìš”",
        ],
        "request": [
            "ëª…í•¨ ì£¼ì„¸ìš”",
            "ìžë£Œ ì¢€ ë³´ë‚´ì£¼ì„¸ìš”",
            "ë¬¸ìžë¡œ ì£¼ì„¸ìš”",
        ],
        "commit": [
            "ê·¸ëŸ¼ í•´ë³¼ê²Œìš”",
            "ì§„í–‰í•´ì£¼ì„¸ìš”",
            "ì‹ ì²­í• ê²Œìš”",
        ]
    },
    "rejection": {
        "hard": [
            "ì•ˆ í•´ìš”",
            "í•„ìš” ì—†ì–´ìš”",
            "ê´€ì‹¬ ì—†ì–´ìš”",
        ],
        "soft": [
            "ë‚˜ì¤‘ì— ì—°ë½ ì£¼ì„¸ìš”",
            "ë‹¤ìŒì— í•´ìš”",
            "ìƒê°í•´ë³¼ê²Œìš”",
        ],
        "busy": [
            "ì§€ê¸ˆ ë°”ë¹ ìš”",
            "ê³ ê° ì‘ëŒ€ ì¤‘ì´ì—ìš”",
            "ì‹œê°„ ì—†ì–´ìš”",
        ]
    },
    "other": {
        "satisfied": [
            "ë‹¤ë¥¸ ë° ë§Œì¡±í•˜ê³  ìžˆì–´ìš”",
            "ì§€ê¸ˆ í•˜ëŠ” ë° ê´œì°®ì•„ìš”",
        ],
        "committed": [
            "ì´ë¯¸ ì •í•´ì§„ ê³³ ìžˆì–´ìš”",
            "ê±°ëž˜ì²˜ ìžˆì–´ì„œìš”",
            "ê³„ì•½ëœ ì—…ì²´ ìžˆì–´ìš”",
        ]
    },
    "greeting": {
        "basic": [
            "ì—¬ë³´ì„¸ìš”",
            "ì•ˆë…•í•˜ì„¸ìš”",
            "ë„¤ ë§ì”€í•˜ì„¸ìš”",
        ]
    }
}

# ============================================================
# HELPER FUNCTIONS
# ============================================================

def make_request(text: str) -> Tuple[Dict, float]:
    """Make API request and return response + elapsed time"""
    payload = {"text": text}
    start_time = time.time()
    
    try:
        response = requests.post(URL, headers=HEADERS, data=json.dumps(payload), timeout=10)
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            return response.json(), elapsed
        else:
            return {"error": f"HTTP {response.status_code}", "text": response.text}, elapsed
    
    except requests.exceptions.Timeout:
        elapsed = time.time() - start_time
        return {"error": "Request timeout"}, elapsed
    
    except Exception as e:
        elapsed = time.time() - start_time
        return {"error": str(e)}, elapsed


def print_response(text: str, result: Dict, elapsed: float, verbose: bool = False):
    """Pretty print a single response"""
    print(f"\nðŸ“ Input: \"{text}\"")
    
    if "error" in result:
        print(f"   âŒ Error: {result['error']}")
        return
    
    intent = result.get('final_intent') or result.get('intent', 'unknown')
    confidence = result.get('confidence', 0)
    sub_context = result.get('sub_context', 'N/A')
    template_ctx = result.get('template_context', 'N/A')
    response = result.get('agent_response', 'N/A')
    
    print(f"   ðŸŽ¯ Intent: {intent} ({confidence:.2%})")
    print(f"   ðŸ“Š Sub-context: {sub_context}")
    print(f"   ðŸ“‹ Template: {template_ctx}")
    print(f"   ðŸ’¬ Response: {response[:80]}{'...' if len(response) > 80 else ''}")
    print(f"   â±ï¸  Time: {elapsed:.3f}s")
    
    if verbose:
        print(f"   ðŸ” Full response:")
        print(json.dumps(result, ensure_ascii=False, indent=4))


# ============================================================
# TEST 1: BASIC FUNCTIONALITY
# ============================================================

def test_basic_functionality():
    """Test basic API connectivity and response format"""
    print("\n" + "="*80)
    print("TEST 1: BASIC FUNCTIONALITY")
    print("="*80)
    
    test_text = "ëª‡ í”„ë¡œì—ìš”?"
    print(f"\nðŸ§ª Testing with: \"{test_text}\"")
    
    result, elapsed = make_request(test_text)
    
    if "error" in result:
        print(f"âŒ FAILED: {result['error']}")
        return False
    
    print("âœ… API is responding")
    
    # Check required fields
    required_fields = ['intent', 'confidence', 'agent_response']
    missing = [f for f in required_fields if f not in result]
    
    if missing:
        print(f"âš ï¸  Missing fields: {missing}")
    else:
        print("âœ… All required fields present")
    
    print_response(test_text, result, elapsed, verbose=True)
    
    return True


# ============================================================
# TEST 2: DETERMINISM
# ============================================================

def test_determinism():
    """Test if same input gives same output"""
    print("\n" + "="*80)
    print("TEST 2: DETERMINISM (Same Input â†’ Same Output)")
    print("="*80)
    
    test_cases = [
        "ëª‡ í”„ë¡œì—ìš”?",
        "ì°¨ì§‘ì‚¬ê°€ ì–´ë””ì—ìš”?",
        "ê´œì°®ë„¤ìš”",
    ]
    
    results = {}
    
    for text in test_cases:
        print(f"\nðŸ” Testing: \"{text}\" (3 attempts)")
        
        attempts = []
        for i in range(3):
            result, elapsed = make_request(text)
            if "error" not in result:
                attempts.append({
                    'intent': result.get('final_intent') or result.get('intent'),
                    'response': result.get('agent_response'),
                    'sub_context': result.get('sub_context'),
                })
            time.sleep(0.1)  # Small delay between requests
        
        # Check consistency
        if len(attempts) == 3:
            intents = [a['intent'] for a in attempts]
            responses = [a['response'] for a in attempts]
            
            intent_consistent = len(set(intents)) == 1
            response_consistent = len(set(responses)) == 1
            
            if intent_consistent and response_consistent:
                print(f"   âœ… DETERMINISTIC")
                print(f"      Intent: {intents[0]}")
                print(f"      Response: {responses[0][:60]}...")
            else:
                print(f"   âŒ NOT DETERMINISTIC")
                print(f"      Intents: {intents}")
                print(f"      Responses differ: {not response_consistent}")
            
            results[text] = intent_consistent and response_consistent
        else:
            print(f"   âŒ Failed to get 3 successful responses")
            results[text] = False
    
    passed = sum(results.values())
    total = len(results)
    print(f"\nðŸ“Š Result: {passed}/{total} passed")
    
    return passed == total


# ============================================================
# TEST 3: CONTEXT AWARENESS
# ============================================================

def test_context_awareness():
    """Test if different sub-contexts get different responses"""
    print("\n" + "="*80)
    print("TEST 3: CONTEXT AWARENESS (Different Questions â†’ Different Answers)")
    print("="*80)
    
    # Test fee questions with different focuses
    print("\nðŸ“Œ Testing fee_question with different contexts:")
    
    fee_tests = [
        ("ëª‡ í”„ë¡œì—ìš”?", "Should focus on amount"),
        ("ì–¸ì œ ìž…ê¸ˆë¼ìš”?", "Should focus on timing"),
        ("ì–´ë–»ê²Œ ì§€ê¸‰í•˜ë‚˜ìš”?", "Should focus on method"),
        ("ì„¸ê¸ˆì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?", "Should mention tax"),
    ]
    
    responses = []
    for text, expected in fee_tests:
        result, elapsed = make_request(text)
        if "error" not in result:
            response = result.get('agent_response', '')
            sub_ctx = result.get('sub_context', 'N/A')
            responses.append({
                'text': text,
                'expected': expected,
                'response': response,
                'sub_context': sub_ctx
            })
            print(f"\n   Input: \"{text}\"")
            print(f"   Expected: {expected}")
            print(f"   Sub-context: {sub_ctx}")
            print(f"   Response: {response[:70]}...")
        time.sleep(0.1)
    
    # Check if responses are different
    unique_responses = len(set(r['response'] for r in responses))
    unique_contexts = len(set(r['sub_context'] for r in responses if r['sub_context'] != 'N/A'))
    
    print(f"\nðŸ“Š Results:")
    print(f"   Unique responses: {unique_responses}/{len(responses)}")
    print(f"   Unique contexts detected: {unique_contexts}/{len(responses)}")
    
    if unique_responses >= 3:
        print(f"   âœ… CONTEXT-AWARE (Multiple different responses)")
    elif unique_responses == 1:
        print(f"   âŒ NOT CONTEXT-AWARE (All same response)")
    else:
        print(f"   âš ï¸  PARTIALLY CONTEXT-AWARE ({unique_responses} different responses)")
    
    return unique_responses >= 3


# ============================================================
# TEST 4: INTENT CLASSIFICATION
# ============================================================

def test_intent_classification():
    """Test if different intents are correctly classified"""
    print("\n" + "="*80)
    print("TEST 4: INTENT CLASSIFICATION")
    print("="*80)
    
    test_samples = {
        "fee_question": ["ëª‡ í”„ë¡œì—ìš”?", "ìˆ˜ìˆ˜ë£Œ ì–¼ë§ˆì£ ?"],
        "about_company": ["ì°¨ì§‘ì‚¬ê°€ ì–´ë””ì—ìš”?", "ë¬´ìŠ¨ íšŒì‚¬ì˜ˆìš”?"],
        "positive": ["ê´œì°®ë„¤ìš”", "ëª…í•¨ ì£¼ì„¸ìš”"],
        "rejection": ["ì•ˆ í•´ìš”", "ë°”ë¹ ìš”"],
        "other": ["ë‹¤ë¥¸ ë° í•˜ê³  ìžˆì–´ìš”", "ê±°ëž˜ì²˜ ìžˆì–´ìš”"],
        "greeting": ["ì—¬ë³´ì„¸ìš”", "ì•ˆë…•í•˜ì„¸ìš”"],
    }
    
    results = defaultdict(lambda: {"correct": 0, "total": 0})
    
    for expected_intent, texts in test_samples.items():
        print(f"\nðŸ“Œ Testing {expected_intent}:")
        
        for text in texts:
            result, elapsed = make_request(text)
            
            if "error" not in result:
                detected = result.get('final_intent') or result.get('intent')
                confidence = result.get('confidence', 0)
                
                is_correct = detected == expected_intent
                results[expected_intent]["total"] += 1
                if is_correct:
                    results[expected_intent]["correct"] += 1
                
                status = "âœ…" if is_correct else "âŒ"
                print(f"   {status} \"{text}\" â†’ {detected} ({confidence:.2%})")
            
            time.sleep(0.1)
    
    # Summary
    print(f"\nðŸ“Š Intent Classification Accuracy:")
    total_correct = 0
    total_samples = 0
    
    for intent, stats in results.items():
        accuracy = stats["correct"] / stats["total"] if stats["total"] > 0 else 0
        total_correct += stats["correct"]
        total_samples += stats["total"]
        print(f"   {intent:20s}: {stats['correct']}/{stats['total']} ({accuracy:.1%})")
    
    overall_accuracy = total_correct / total_samples if total_samples > 0 else 0
    print(f"\n   {'Overall':20s}: {total_correct}/{total_samples} ({overall_accuracy:.1%})")
    
    return overall_accuracy >= 0.8  # 80% threshold


# ============================================================
# TEST 5: RESPONSE VARIETY
# ============================================================

def test_response_variety():
    """Test if system has good variety in responses"""
    print("\n" + "="*80)
    print("TEST 5: RESPONSE VARIETY")
    print("="*80)
    
    all_responses = []
    all_hashes = set()
    
    for intent, contexts in TEST_CASES.items():
        for context, texts in contexts.items():
            # Test first text from each context
            if texts:
                text = texts[0]
                result, _ = make_request(text)
                
                if "error" not in result:
                    response = result.get('agent_response', '')
                    all_responses.append({
                        'intent': intent,
                        'context': context,
                        'text': text,
                        'response': response
                    })
                    # Create a simple hash of response
                    response_hash = hash(response)
                    all_hashes.add(response_hash)
                
                time.sleep(0.1)
    
    print(f"\nðŸ“Š Variety Analysis:")
    print(f"   Total test cases: {len(all_responses)}")
    print(f"   Unique responses: {len(all_hashes)}")
    print(f"   Variety ratio: {len(all_hashes)/len(all_responses):.1%}")
    
    # Group by intent to see variety within intents
    by_intent = defaultdict(list)
    for r in all_responses:
        by_intent[r['intent']].append(r['response'])
    
    print(f"\nðŸ“‹ Variety by Intent:")
    for intent, responses in by_intent.items():
        unique = len(set(responses))
        total = len(responses)
        print(f"   {intent:20s}: {unique}/{total} unique responses")
    
    variety_ratio = len(all_hashes) / len(all_responses) if all_responses else 0
    return variety_ratio >= 0.7  # At least 70% unique responses


# ============================================================
# TEST 6: EDGE CASES
# ============================================================

def test_edge_cases():
    """Test edge cases and error handling"""
    print("\n" + "="*80)
    print("TEST 6: EDGE CASES")
    print("="*80)
    
    edge_cases = [
        ("", "Empty string"),
        ("ã…‹ã…‹ã…‹ã…‹", "Only consonants"),
        ("ì•„ ë­ ì–´ì©Œë¼ê³ ", "Vague/unclear"),
        ("ê·¸ê²Œ ê·¸ê±°ê³  ì €ê²Œ ì €ê±°ìž–ì•„ìš”", "Nonsensical"),
        ("a b c d e f", "English letters"),
        ("123456", "Numbers only"),
    ]
    
    results = []
    
    for text, description in edge_cases:
        print(f"\nðŸ§ª Testing: \"{text}\" ({description})")
        result, elapsed = make_request(text)
        
        if "error" in result:
            print(f"   âš ï¸  Error: {result['error']}")
            results.append(False)
        else:
            intent = result.get('final_intent') or result.get('intent')
            confidence = result.get('confidence', 0)
            response = result.get('agent_response', '')
            
            # Should fallback to 'fallback' intent for unclear inputs
            is_handled = len(response) > 0
            
            print(f"   Intent: {intent} ({confidence:.2%})")
            print(f"   Response: {response[:60]}...")
            print(f"   {'âœ… Handled' if is_handled else 'âŒ Not handled'}")
            
            results.append(is_handled)
        
        time.sleep(0.1)
    
    handled = sum(results)
    total = len(results)
    print(f"\nðŸ“Š Edge cases handled: {handled}/{total}")
    
    return handled >= total * 0.8  # 80% should be handled


# ============================================================
# MAIN TEST RUNNER
# ============================================================

def run_all_tests():
    """Run all tests and generate report"""
    print("\n" + "="*80)
    print("ðŸ§ª COMPREHENSIVE TEST SUITE")
    print("="*80)
    print(f"Testing URL: {URL}")
    print("="*80)
    
    tests = [
        ("Basic Functionality", test_basic_functionality),
        ("Determinism", test_determinism),
        ("Context Awareness", test_context_awareness),
        ("Intent Classification", test_intent_classification),
        ("Response Variety", test_response_variety),
        ("Edge Cases", test_edge_cases),
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        try:
            passed = test_func()
            results[test_name] = passed
        except Exception as e:
            print(f"\nâŒ Test '{test_name}' failed with exception: {e}")
            results[test_name] = False
        
        time.sleep(0.5)  # Delay between tests
    
    # Final Report
    print("\n" + "="*80)
    print("ðŸ“Š FINAL REPORT")
    print("="*80)
    
    for test_name, passed in results.items():
        status = "âœ… PASSED" if passed else "âŒ FAILED"
        print(f"{status:12s} | {test_name}")
    
    passed_count = sum(results.values())
    total_count = len(results)
    
    print("="*80)
    print(f"Overall: {passed_count}/{total_count} tests passed ({passed_count/total_count*100:.1f}%)")
    print("="*80)
    
    if passed_count == total_count:
        print("\nðŸŽ‰ All tests passed! Your system is working perfectly!")
    elif passed_count >= total_count * 0.8:
        print("\nðŸ‘ Most tests passed. Some minor issues to address.")
    else:
        print("\nâš ï¸  Several tests failed. Review the results above.")


# ============================================================
# QUICK TEST (FOR DEBUGGING)
# ============================================================

def quick_test(text: str):
    """Quick single test for debugging"""
    print(f"\nðŸ” Quick Test: \"{text}\"")
    print("="*80)
    
    result, elapsed = make_request(text)
    print_response(text, result, elapsed, verbose=True)


# ============================================================
# MAIN
# ============================================================

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        # Quick test mode with command line argument
        test_text = " ".join(sys.argv[1:])
        quick_test(test_text)
    else:
        # Run full test suite
        run_all_tests()