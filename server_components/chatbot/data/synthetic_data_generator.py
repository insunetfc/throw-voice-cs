import pandas as pd
import random

class SyntheticDataGenerator:
    """
    Generate synthetic training data based on promotional call scripts.
    Creates realistic dealer responses to different parts of the pitch.
    """
    
    def __init__(self):
        # Script key points that trigger specific dealer responses
        self.script_triggers = {
            'fee_mention': ['7%', 'ë³´í—˜ë£Œì˜ 7%', 'ìˆ˜ìˆ˜ë£Œ', 'ìµì¼ ì§€ê¸‰'],
            'company_mention': ['ì°¨ì§‘ì‚¬', 'ì¸ìŠˆë„·', 'FC ì œíœ´ì‚¬', 'ë‹¤ì´ë ‰íŠ¸'],
            'service_mention': ['AI 1668-4007', 'ê¸´ê¸‰ì¶œë™', 'ë³´í—˜ì‚¬ ì§ì ‘ ì—°ê²°', 'ë¹„êµ'],
            'benefit_mention': ['CU 5ì²œì›', 'CUí¸ì˜ì ', 'ìƒí’ˆê¶Œ', 'ì²´ê²°ìœ¨ 95%']
        }
        
        # Synthetic response templates for each intent
        self.synthetic_templates = {
            'fee_question': [
                "ëª‡ í”„ë¡œ ì¤€ë‹¤ê³ ìš”?",
                "ìˆ˜ìˆ˜ë£Œê°€ ì •í™•íˆ ì–¼ë§ˆì£ ?",
                "{x}% ì£¼ëŠ” ê±°ì˜ˆìš”?",
                "ì–¸ì œ ì…ê¸ˆë¼ìš”?",
                "ì •ì‚°ì€ ì–¸ì œ ë˜ë‚˜ìš”?",
                "ë‹¤ë¥¸ ë°ë³´ë‹¤ ë§ì´ ì£¼ë‚˜ìš”?",
                "ì¡°ê±´ì´ ì–´ë–»ê²Œ ë˜ì£ ?",
                "ê·¸ëŸ¼ {x}%ê°€ ë§ëŠ” ê±°ì£ ?",
                "ë‹¤ì´ë ‰íŠ¸ë„ ë˜‘ê°™ì´ {x}%ì¸ê°€ìš”?",
                "ì„¸ê¸ˆì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                "ì§€ê¸‰ ì¡°ê±´ ì¢€ ë” ìì„¸íˆ ì•Œë ¤ì£¼ì„¸ìš”",
                "ìµì¼ì´ë©´ ë‹¤ìŒë‚ ì´ì—ìš”?",
                "ê³„ì¢Œë¡œ ë°”ë¡œ ë“¤ì–´ì˜¤ëŠ” ê±´ê°€ìš”?",
                "ìµœì†Œ ê¸ˆì•¡ ê°™ì€ ê±° ìˆì–´ìš”?",
                "ì›”ë§ ì •ì‚°ì¸ê°€ìš”?",
            ],
            'about_company': [
                "ì°¨ì§‘ì‚¬ê°€ ì–´ë””ì˜ˆìš”?",
                "ì–´ëŠ íšŒì‚¬ì£ ?",
                "ì •ì‹ ì—…ì²´ ë§ë‚˜ìš”?",
                "ë³´í—˜ì‚¬ë‘ ë¬´ìŠ¨ ê´€ê³„ì£ ?",
                "ì¸ìŠˆë„·ì´ ë­ì˜ˆìš”?",
                "ì œíœ´ì‚¬ë¼ëŠ” ê²Œ ë­”ê°€ìš”?",
                "ë³¸ì‚¬ëŠ” ì–´ë”” ìˆì–´ìš”?",
                "ë“±ë¡ëœ íšŒì‚¬ì˜ˆìš”?",
                "ì²˜ìŒ ë“£ëŠ”ë°ìš”?",
                "ì–´ë”” ì†Œì†ì´ì„¸ìš”?",
                "ì¤‘ê°œ ì—…ì²´ì¸ê°€ìš”?",
                "ë³´í—˜ì‚¬ ì§ì˜ì´ì—ìš”?",
                "ë²•ì¸ ì‚¬ì—…ìì˜ˆìš”?",
                "ê³ ê°ì„¼í„° ë²ˆí˜¸ ìˆì–´ìš”?",
                "ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê³³ì¸ê°€ìš”?",
            ],
            'more_questions': [
                "ê³ ê°ì´ ì§ˆë¬¸í•˜ë©´ ì–´ë–»ê²Œ í•´ìš”?",
                "ë³´í—˜ ë¹„êµëŠ” ì–´ë–»ê²Œ í•˜ëŠ” ê±°ì˜ˆìš”?",
                "ê¸´ê¸‰ì¶œë™ì´ ë­ì˜ˆìš”?",
                "AI ë²ˆí˜¸ê°€ ë­”ê°€ìš”?",
                "ê³ ê°í•œí…Œ ë­ë¼ê³  ì„¤ëª…í•´ì•¼ ë¼ìš”?",
                "ì ˆì°¨ê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                "ìƒë‹´ ì—°ê²°ì€ ì–¼ë§ˆë‚˜ ê±¸ë ¤ìš”?",
                "ê³ ê° ì •ë³´ëŠ” ë­ê°€ í•„ìš”í•´ìš”?",
                "ê²¬ì ì€ ëª‡ ë¶„ ë§Œì— ë‚˜ì™€ìš”?",
                "ëª¨ë°”ì¼ë¡œë„ ë˜ë‚˜ìš”?",
                "ê³„ì•½ì„œëŠ” ì–´ë–»ê²Œ ë°›ì•„ìš”?",
                "ì‚¬ê³  ë‚¬ì„ ë•Œë„ ì—°ë½ ê°€ëŠ¥í•´ìš”?",
                "ë³´ì¥ ë‚´ìš© í™•ì¸ ê°€ëŠ¥í•œê°€ìš”?",
                "ì—¬ëŸ¬ ë³´í—˜ì‚¬ ë‹¤ ë˜ë‚˜ìš”?",
                "ê°±ì‹  ê³ ê°ë„ ê°€ëŠ¥í•´ìš”?",
            ],
            'positive': [
                "ì˜¤ ê´œì°®ë„¤ìš”",
                "ì¢‹ì€ ì¡°ê±´ì´ë„¤ìš”",
                "í•œë²ˆ í•´ë³¼ê²Œìš”",
                "ëª…í•¨ ì£¼ì„¸ìš”",
                "ë¬¸ìë¡œ ë³´ë‚´ì£¼ì„¸ìš”",
                "ìë£Œ ì¢€ ì£¼ì‹¤ë˜ìš”?",
                "ê·¸ëŸ¼ ì§„í–‰í•´ë³¼ê²Œìš”",
                "ì—°ë½ì²˜ ë‚¨ê²¨ì£¼ì„¸ìš”",
                "ë‚˜ì¤‘ì— ì—°ë½ë“œë¦´ê²Œìš”",
                "ìƒê°ë³´ë‹¤ ê´œì°®ì€ë°ìš”",
                "ê³ ê°í•œí…Œ ì†Œê°œí•´ë³¼ê²Œìš”",
                "ë§í¬ ì¢€ ì£¼ì„¸ìš”",
                "ì¹´í†¡ìœ¼ë¡œ ì£¼ì„¸ìš”",
                "ì¼ë‹¨ ë°›ì•„ë†“ì„ê²Œìš”",
                "ì €ì¥í•´ë‘˜ê²Œìš”",
            ],
            'rejection': [
                "ì§€ê¸ˆì€ ì•ˆ í•´ìš”",
                "ê´€ì‹¬ ì—†ì–´ìš”",
                "ë°”ë¹ ì„œìš”",
                "ë‚˜ì¤‘ì—ìš”",
                "ëì–´ìš”",
                "ì•ˆ í•  ê±°ì˜ˆìš”",
                "í•„ìš” ì—†ì–´ìš”",
                "ì „í™” ëŠì„ê²Œìš”",
                "ì‹œê°„ ì—†ì–´ìš”",
                "ê·€ì°®ì•„ìš”",
                "ë‹¤ìŒì— í•´ìš”",
                "ë³„ë¡œë„¤ìš”",
                "ì•ˆ ë§ì•„ìš”",
                "ê·¸ë§Œí•˜ì„¸ìš”",
                "ê³ ê°ë“¤ì´ ì‹«ì–´í•´ìš”",
            ],
            'other': [
                "ì € ë‹¤ë¥¸ ë° í•˜ê³  ìˆì–´ìš”",
                "ì´ë¯¸ ê±°ë˜ì²˜ ìˆì–´ìš”",
                "ê³ ì • ì—…ì²´ ìˆì–´ì„œìš”",
                "ë§¡ê¸°ëŠ” ê³³ì´ ìˆì–´ìš”",
                "ë‹¤ë¥¸ ë°ë§Œ ì¨ìš”",
                "ê³„ì† í•˜ë˜ ë°ê°€ ìˆì–´ì„œìš”",
                "íŒŒíŠ¸ë„ˆì‚¬ ìˆì–´ìš”",
                "ì œíœ´ì‚¬ ì •í•´ì ¸ ìˆì–´ìš”",
                "ê¸°ì¡´ ë‹´ë‹¹ì ìˆì–´ìš”",
                "ë¯¿ëŠ” ê³³ì´ ìˆì–´ì„œìš”",
                "ë°”ê¿€ ìƒê° ì—†ì–´ìš”",
                "ì˜¤ë˜ ê±°ë˜í•˜ëŠ” ê³³ ìˆì–´ìš”",
                "ë§Œì¡±í•˜ëŠ” ì—…ì²´ ìˆì–´ìš”",
                "í•œ êµ°ë°ë§Œ ì¨ìš”",
                "ì •í•´ì§„ ë£¨íŠ¸ê°€ ìˆì–´ìš”",
            ],
            'fallback': [
                "ìë£Œ ì¢€ ì£¼ì„¸ìš”",
                "ì–´ë–»ê²Œ ì‹œì‘í•˜ë‚˜ìš”?",
                "ê³ ê°í•œí…Œ ë­ë¼ê³  í•´ìš”?",
                "ëª…í•¨ ìˆì–´ìš”?",
                "ë§í¬ ì£¼ì„¸ìš”",
                "ë¬¸ìë¡œ ë³´ë‚´ì£¼ì„¸ìš”",
                "ì¹´í†¡ ë¼ìš”?",
                "ì„¤ëª… ìë£Œ ìˆì–´ìš”?",
                "í…œí”Œë¦¿ ê°™ì€ ê±°ìš”?",
                "ìƒë‹´ì› ë²ˆí˜¸ ì£¼ì„¸ìš”",
                "ë‹´ë‹¹ì ì—°ê²°í•´ì£¼ì„¸ìš”",
                "ì´ë¯¸ì§€ë¡œ ì£¼ì‹¤ ìˆ˜ ìˆì–´ìš”?",
                "PDF ìˆë‚˜ìš”?",
                "ê³µìœ í•´ë„ ë¼ìš”?",
                "ì¶œë ¥ ê°€ëŠ¥í•´ìš”?",
            ],
            'greeting': [
                "ì—¬ë³´ì„¸ìš”",
                "ë„¤ ë§ì”€í•˜ì„¸ìš”",
                "ì–´ë””ì„¸ìš”?",
                "ëˆ„êµ¬ì‹œì£ ?",
                "ì•ˆë…•í•˜ì„¸ìš”",
                "ë„¤ë„¤",
                "ì˜ˆ",
                "ì „í™” ë°›ì•˜ì–´ìš”",
                "ë§ì”€í•˜ì„¸ìš”",
                "ì–´ë”” ì „í™”ì˜ˆìš”?",
            ]
        }
    
    def generate_variations(self, template, count=3):
        """Generate variations of a template"""
        variations = []
        
        if '{x}' in template:
            # Replace with common percentages
            percentages = ['5', '7', '10', '3']
            for pct in random.sample(percentages, min(count, len(percentages))):
                variations.append(template.replace('{x}', pct))
        else:
            # Just return the template multiple times with slight variations
            variations = [template] * min(count, 1)
        
        return variations
    
    def generate_synthetic_data(self, samples_per_class=30):
        """Generate synthetic training data"""
        synthetic_data = []
        
        for intent, templates in self.synthetic_templates.items():
            # Generate samples for this intent
            samples_generated = 0
            
            while samples_generated < samples_per_class:
                for template in templates:
                    if samples_generated >= samples_per_class:
                        break
                    
                    # Generate variations
                    variations = self.generate_variations(template, count=2)
                    
                    for var in variations:
                        if samples_generated >= samples_per_class:
                            break
                        
                        synthetic_data.append({
                            'question': var,
                            'label': intent
                        })
                        samples_generated += 1
        
        return pd.DataFrame(synthetic_data)
    
    def merge_with_existing(self, existing_csv, output_csv, samples_per_class=20):
        """Merge synthetic data with existing dataset"""
        
        # Load existing data
        existing_df = pd.read_csv(existing_csv)
        existing_df = existing_df.dropna(subset=['label'])
        
        print(f"ğŸ“Š Existing dataset: {len(existing_df)} samples")
        print(existing_df['label'].value_counts())
        
        # Generate synthetic data
        print(f"\nğŸ”„ Generating {samples_per_class} synthetic samples per class...")
        synthetic_df = self.generate_synthetic_data(samples_per_class=samples_per_class)
        
        print(f"\nğŸ“Š Synthetic dataset: {len(synthetic_df)} samples")
        print(synthetic_df['label'].value_counts())
        
        # Merge
        combined_df = pd.concat([existing_df, synthetic_df], ignore_index=True)
        combined_df = combined_df.drop_duplicates(subset=['question'])
        
        # Save
        combined_df.to_csv(output_csv, index=False)
        
        print(f"\n{'='*60}")
        print(f"âœ… Combined dataset saved: {output_csv}")
        print(f"Total samples: {len(combined_df)}")
        print(f"Increase: +{len(combined_df) - len(existing_df)} samples")
        print(f"\nğŸ“Š Final distribution:")
        print(combined_df['label'].value_counts())
        print(f"{'='*60}")
        
        return combined_df


def create_conversation_flow_guide():
    """Create a guide for using the model in conversation flow"""
    
    flow_guide = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘          ì°¨ì§‘ì‚¬ í”„ë¡œëª¨ì…˜ ì½œ - ëŒ€í™” íë¦„ ê°€ì´ë“œ                    â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    1ï¸âƒ£ GREETING (ì¸ì‚¬)
       ë”œëŸ¬ ì‘ë‹µ: "ì—¬ë³´ì„¸ìš”", "ì•ˆë…•í•˜ì„¸ìš”"
       â†’ ë‹¤ìŒ ì•¡ì…˜: ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ (íšŒì‚¬ ì†Œê°œ + ì„œë¹„ìŠ¤ ì„¤ëª…)
    
    2ï¸âƒ£ ABOUT_COMPANY (íšŒì‚¬ ì •ë³´)
       ë”œëŸ¬ ì‘ë‹µ: "ì°¨ì§‘ì‚¬ê°€ ë­ì˜ˆìš”?", "ì–´ë”” íšŒì‚¬ì˜ˆìš”?"
       â†’ ë‹¤ìŒ ì•¡ì…˜: 
          - ì¸ìŠˆë„· FC ì œíœ´ì‚¬ ì„¤ëª…
          - 40ë…„ ì „í†µ, ë³´í—˜ì‚¬ ì—°ë„ëŒ€ìƒì ì¶œì‹  íŒ€ ê°•ì¡°
          - ì •ì‹ ë“±ë¡ ì—…ì²´ì„ì„ ì•ˆë‚´
    
    3ï¸âƒ£ FEE_QUESTION (ìˆ˜ìˆ˜ë£Œ ë¬¸ì˜)
       ë”œëŸ¬ ì‘ë‹µ: "ëª‡ % ì£¼ëŠ”ë°ìš”?", "ìˆ˜ìˆ˜ë£Œê°€ ì–¼ë§ˆì£ ?"
       â†’ ë‹¤ìŒ ì•¡ì…˜:
          - "7% ìµì¼ ì§€ê¸‰" ëª…í™•íˆ ì „ë‹¬
          - OFF/TM/CM ëª¨ë‘ ë™ì¼ ì¡°ê±´ ê°•ì¡°
          - ì²´ê²°ìœ¨ 95% ì´ìƒ ì–¸ê¸‰
    
    4ï¸âƒ£ MORE_QUESTIONS (ì„œë¹„ìŠ¤ ë¬¸ì˜)
       ë”œëŸ¬ ì‘ë‹µ: "ì ˆì°¨ê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?", "ê³ ê°ì´ ì§ˆë¬¸í•˜ë©´?"
       â†’ ë‹¤ìŒ ì•¡ì…˜:
          - AI ARS 1668-4007 ê¸´ê¸‰ì¶œë™ ì„œë¹„ìŠ¤ ì„¤ëª…
          - 10ë¶„ ë‚´ ë¹„êµ ê²¬ì  ì œê³µ
          - ë³´í—˜ì‚¬ ì§ì ‘ ì—°ê²° ì„œë¹„ìŠ¤ ì„¤ëª…
          - ë”œëŸ¬ì—ê²Œ ë³´í—˜ ë¬¸ì˜ ì•ˆ ê° ê°•ì¡°
    
    5ï¸âƒ£ POSITIVE (ê¸ì • ë°˜ì‘)
       ë”œëŸ¬ ì‘ë‹µ: "ê´œì°®ë„¤ìš”", "ëª…í•¨ ì£¼ì„¸ìš”", "í•´ë³¼ê²Œìš”"
       â†’ ë‹¤ìŒ ì•¡ì…˜:
          - ëª…í•¨/ìë£Œ ë¬¸ì ë°œì†¡
          - CU 5ì²œì›ê¶Œ í˜œíƒ ì¬ì•ˆë‚´
          - ë‹´ë‹¹ ìƒë‹´ì› ì—°ë½ì²˜ ê³µìœ 
          - "ì²« ê²¬ì  ë¬¸ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤" ë§ˆë¬´ë¦¬
    
    6ï¸âƒ£ REJECTION (ê±°ì ˆ)
       ë”œëŸ¬ ì‘ë‹µ: "ì•ˆ í•´ìš”", "ê´€ì‹¬ ì—†ì–´ìš”", "ë°”ë¹ ìš”"
       â†’ ë‹¤ìŒ ì•¡ì…˜:
          - ì •ì¤‘í•˜ê²Œ ìˆ˜ìš©
          - "ëª…í•¨ë§Œ ë‚¨ê²¨ë“œë¦´ê²Œìš”" (ë¶€ë“œëŸ½ê²Œ)
          - "ë‚˜ì¤‘ì— í•„ìš”í•˜ì‹œë©´ ì—°ë½ì£¼ì„¸ìš”" ë§ˆë¬´ë¦¬
          - ë” ì´ìƒ í‘¸ì‹œí•˜ì§€ ì•Šê¸°
    
    7ï¸âƒ£ OTHER (ê¸°ì¡´ ê±°ë˜ì²˜)
       ë”œëŸ¬ ì‘ë‹µ: "ë‹¤ë¥¸ ë° í•˜ê³  ìˆì–´ìš”", "ê±°ë˜ì²˜ ìˆì–´ìš”"
       â†’ ë‹¤ìŒ ì•¡ì…˜:
          - "ë¹„êµë§Œ í•´ë³´ì„¸ìš”" ì œì•ˆ
          - 7% + ì²´ê²°ìœ¨ 95% ì¡°ê±´ ì°¨ë³„í™”
          - "ê¸°ì¡´ ê±°ë˜ì²˜ì™€ ë¹„êµ í›„ ê²°ì •í•˜ì…”ë„ ë©ë‹ˆë‹¤"
          - ëª…í•¨ ë‚¨ê¸°ê³  ë¶€ë“œëŸ½ê²Œ ë§ˆë¬´ë¦¬
    
    8ï¸âƒ£ FALLBACK (ìë£Œ ìš”ì²­)
       ë”œëŸ¬ ì‘ë‹µ: "ìë£Œ ì£¼ì„¸ìš”", "ë§í¬ ì£¼ì„¸ìš”", "ì¹´í†¡ìœ¼ë¡œ?"
       â†’ ë‹¤ìŒ ì•¡ì…˜:
          - ì¦‰ì‹œ ëª…í•¨/ìë£Œ ë¬¸ì ë°œì†¡
          - ì¹´ì¹´ì˜¤í†¡ ì±„ë„ ì•ˆë‚´ (ìˆëŠ” ê²½ìš°)
          - ìƒë‹´ì› ì§ì ‘ ì—°ê²° ì œì•ˆ
          - "í•„ìš”í•˜ì‹œë©´ ë°”ë¡œ ì—°ë½ì£¼ì„¸ìš”" ì•ˆë‚´
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ğŸ’¡ Pro Tips:
    
    â€¢ ì—°ì†ëœ rejection â†’ ì •ì¤‘í•˜ê²Œ í†µí™” ì¢…ë£Œ
    â€¢ positive í›„ fee_question â†’ ì ê·¹ ì‘ëŒ€ (ë†’ì€ ê´€ì‹¬ë„)
    â€¢ greeting â†’ about_company ìˆœì„œëŠ” ìì—°ìŠ¤ëŸ¬ìš´ íë¦„
    â€¢ other ì‘ë‹µì— ë„ˆë¬´ í‘¸ì‹œí•˜ì§€ ë§ ê²ƒ (ì—­íš¨ê³¼)
    â€¢ fallbackì€ ê¸ì • ì‹ í˜¸ - ì ê·¹ ìë£Œ ì œê³µ
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    
    print(flow_guide)
    
    # Save to file
    with open('./model/conversation_flow_guide.txt', 'w', encoding='utf-8') as f:
        f.write(flow_guide)
    
    print("âœ… Conversation flow guide saved to: ./model/conversation_flow_guide.txt")


def main():
    """Main function to generate and merge synthetic data"""
    
    print("="*60)
    print("ğŸ¤– Synthetic Training Data Generator")
    print("="*60)
    
    generator = SyntheticDataGenerator()
    
    # Generate and merge with existing data
    combined_df = generator.merge_with_existing(
        existing_csv='./data/intent_dataset.csv',
        output_csv='./data/intent_dataset_enhanced.csv',
        samples_per_class=25  # Add 25 synthetic samples per class
    )
    
    # Create conversation flow guide
    print("\n" + "="*60)
    print("ğŸ“– Creating Conversation Flow Guide")
    print("="*60)
    create_conversation_flow_guide()
    
    print("\n" + "="*60)
    print("âœ… All Done!")
    print("="*60)
    print("\nNext steps:")
    print("1. Review: ./data/intent_dataset_enhanced.csv")
    print("2. Train: python train.py (use enhanced dataset)")
    print("3. Review: ./model/conversation_flow_guide.txt")
    print("="*60)


if __name__ == "__main__":
    main()